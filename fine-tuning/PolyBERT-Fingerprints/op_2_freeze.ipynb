{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from psmiles import PolymerSmiles as PS\n",
    "from sklearn.metrics  import  mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.trial import TrialState \n",
    "\n",
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:2\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../data/updated_polymers.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "data = df[\"fingerprint_polyBERT\"]\n",
    "target = df[\"Egc\"]\n",
    "\n",
    "#data = data.values.reshape(-1, 1)  # Reshape data\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=123)\n",
    "\n",
    "# Scaling target variable\n",
    "target_train = scalar.fit_transform(target_train.values.reshape(-1, 1))\n",
    "target_test = scalar.transform(target_test.values.reshape(-1, 1))\n",
    "\n",
    "# Creating tensors from data\n",
    "\n",
    "#Training Data\n",
    "data_train_tensor = torch.tensor(data_train.reset_index(drop = True), dtype=torch.float32)\n",
    "target_train_tensor = torch.tensor(target_train, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(data_train_tensor, target_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size= 32, shuffle= True)\n",
    "\n",
    "#Testing Data\n",
    "\n",
    "data_test_tensor = torch.tensor(data_test.reset_index(drop= True), dtype=torch.float32)\n",
    "target_test_tensor = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(data_test_tensor, target_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    layers =  nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(600, 1504),\n",
    "                nn.Dropout(0.122517721),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1504, 1760),\n",
    "                nn.Dropout(0.125659318),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1760, 736),\n",
    "                nn.Dropout(0.125674157),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            \n",
    "            nn.Linear(736, 1)\n",
    "        ])\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    \n",
    "    model = define_model(trial)\n",
    "    state_dict = torch.load('../models/molecule_circular.pth')\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 0.00020108, log = True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    EPOCHS  = trial.suggest_int(\"EPOCHS\", 50, 700)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx,(data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(DEVICE), target.view(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.mse_loss(output.view(-1), target)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss = running_loss / batch_idx\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                pred = model(data)\n",
    "                target_scaled = scalar.inverse_transform(target.cpu().numpy())\n",
    "                pred_scaled = scalar.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "                test_loss = mean_squared_error(target_scaled, pred_scaled)\n",
    "                val_loss  += test_loss\n",
    "\n",
    "        avg_val_loss = val_loss/ batch_idx \n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    \n",
    "    model = define_model(trial)\n",
    "    state_dict = torch.load('../models/molecule_circular.pth')\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if '0.0' in name or '0.2' in name or '1.0' in name or '1.2' in name:\n",
    "            param.requires_grad = False\n",
    "            \n",
    "    # Generate the optimizers.\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log = True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    EPOCHS  = trial.suggest_int(\"EPOCHS\", 50, 700)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx,(data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(DEVICE), target.view(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.mse_loss(output.view(-1), target)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss = running_loss / batch_idx\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                pred = model(data)\n",
    "                target_scaled = scalar.inverse_transform(target.cpu().numpy())\n",
    "                pred_scaled = scalar.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "                test_loss = mean_squared_error(target_scaled, pred_scaled)\n",
    "                val_loss  += test_loss\n",
    "\n",
    "        avg_val_loss = val_loss/ batch_idx \n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials = 12000, n_jobs= 5)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    # Save results to csv file\n",
    "    df = study.trials_dataframe().drop(['datetime_start', 'datetime_complete', 'duration'], axis=1)  # Exclude columns\n",
    "    df = df.loc[df['state'] == 'COMPLETE']        # Keep only results that did not prune\n",
    "    df = df.drop('state', axis=1)                 # Exclude state column\n",
    "    df = df.sort_values('value')                  # Sort based on accuracy\n",
    "    df.to_csv('op_2_freeze.csv', index=False)  # Save to csv file\n",
    "\n",
    "    # Display results in a dataframe\n",
    "    print(\"\\nOverall Results (ordered by accuracy):\\n {}\".format(df))\n",
    "\n",
    "    # Find the most important hyperparameters\n",
    "    most_important_parameters = optuna.importance.get_param_importances(study, target=None)\n",
    "\n",
    "    # Display the most important hyperparameters\n",
    "    print('\\nMost important hyperparameters:')\n",
    "    for key, value in most_important_parameters.items():\n",
    "        print('  {}:{}{:.2f}%'.format(key, (15-len(key))*' ', value*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
