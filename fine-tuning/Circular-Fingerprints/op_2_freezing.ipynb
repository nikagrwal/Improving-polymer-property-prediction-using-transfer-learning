{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikita/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from psmiles import PolymerSmiles as PS\n",
    "from sklearn.metrics  import  mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.trial import TrialState \n",
    "\n",
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>Egc</th>\n",
       "      <th>fingerprint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>[*]C[*]</td>\n",
       "      <td>6.8972</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>[*]CC([*])C</td>\n",
       "      <td>6.5196</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>[*]CC([*])CC</td>\n",
       "      <td>6.5170</td>\n",
       "      <td>[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>[*]CC([*])CCC</td>\n",
       "      <td>6.7336</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>[*]CC([*])CC(C)C</td>\n",
       "      <td>6.7394</td>\n",
       "      <td>[0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               smiles     Egc   \n",
       "822           [*]C[*]  6.8972  \\\n",
       "823       [*]CC([*])C  6.5196   \n",
       "824      [*]CC([*])CC  6.5170   \n",
       "825     [*]CC([*])CCC  6.7336   \n",
       "826  [*]CC([*])CC(C)C  6.7394   \n",
       "\n",
       "                                           fingerprint  \n",
       "822  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "823  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "824  [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "825  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "826  [0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/updated_polymers.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2266311/3667220817.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  data_train_tensor = torch.tensor(data_train.reset_index(drop = True), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "scalar = MinMaxScaler()\n",
    "data = df[\"fingerprint_circular\"]\n",
    "target = df[\"Egc\"]\n",
    "\n",
    "#data = data.values.reshape(-1, 1)  # Reshape data\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.2, random_state=123)\n",
    "\n",
    "# Scaling target variable\n",
    "target_train = scalar.fit_transform(target_train.values.reshape(-1, 1))\n",
    "target_test = scalar.transform(target_test.values.reshape(-1, 1))\n",
    "\n",
    "# Creating tensors from data\n",
    "\n",
    "#Training Data\n",
    "data_train_tensor = torch.tensor(data_train.reset_index(drop = True), dtype=torch.float32)\n",
    "target_train_tensor = torch.tensor(target_train, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(data_train_tensor, target_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size= 32, shuffle= True)\n",
    "\n",
    "#Testing Data\n",
    "\n",
    "data_test_tensor = torch.tensor(data_test.reset_index(drop= True), dtype=torch.float32)\n",
    "target_test_tensor = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(data_test_tensor, target_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    layers =  nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2048, 1888),\n",
    "                nn.Dropout(0.296708814),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1888, 416),\n",
    "                nn.Dropout(0.103316943),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(416, 1632),\n",
    "                nn.Dropout(0.178598433),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            \n",
    "            nn.Linear(1632, 1)\n",
    "        ])\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    \n",
    "    model = define_model(trial)\n",
    "    state_dict = torch.load('../models/molecule_circular.pth')\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if '0.0' in name or '0.2' in name or '1.0' in name or '1.2' in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "  \n",
    "    # Generate the optimizers.\n",
    "    lr = 0.000364567\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    EPOCHS  = trial.suggest_int(\"EPOCHS\", 50, 700)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx,(data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(DEVICE), target.view(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.mse_loss(output.view(-1), target)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss = running_loss / batch_idx\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                pred = model(data)\n",
    "                target_scaled = scalar.inverse_transform(target.cpu().numpy())\n",
    "                pred_scaled = scalar.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "                test_loss = mean_squared_error(target_scaled, pred_scaled)\n",
    "                val_loss  += test_loss\n",
    "\n",
    "        avg_val_loss = val_loss/ batch_idx \n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-28 23:56:32,275] A new study created in memory with name: no-name-36513174-d582-49ef-8be1-837223b4a82f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.children of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1888, bias=True)\n",
      "    (1): Dropout(p=0.296708814, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1888, out_features=416, bias=True)\n",
      "    (1): Dropout(p=0.103316943, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=416, out_features=1632, bias=True)\n",
      "    (1): Dropout(p=0.178598433, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (3): Linear(in_features=1632, out_features=1, bias=True)\n",
      ")>\n",
      "<bound method Module.children of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1888, bias=True)\n",
      "    (1): Dropout(p=0.296708814, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1888, out_features=416, bias=True)\n",
      "    (1): Dropout(p=0.103316943, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=416, out_features=1632, bias=True)\n",
      "    (1): Dropout(p=0.178598433, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (3): Linear(in_features=1632, out_features=1, bias=True)\n",
      ")>\n",
      "<bound method Module.children of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1888, bias=True)\n",
      "    (1): Dropout(p=0.296708814, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1888, out_features=416, bias=True)\n",
      "    (1): Dropout(p=0.103316943, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=416, out_features=1632, bias=True)\n",
      "    (1): Dropout(p=0.178598433, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (3): Linear(in_features=1632, out_features=1, bias=True)\n",
      ")>\n",
      "<bound method Module.children of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1888, bias=True)\n",
      "    (1): Dropout(p=0.296708814, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1888, out_features=416, bias=True)\n",
      "    (1): Dropout(p=0.103316943, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=416, out_features=1632, bias=True)\n",
      "    (1): Dropout(p=0.178598433, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (3): Linear(in_features=1632, out_features=1, bias=True)\n",
      ")>\n",
      "<bound method Module.children of Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=1888, bias=True)\n",
      "    (1): Dropout(p=0.296708814, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=1888, out_features=416, bias=True)\n",
      "    (1): Dropout(p=0.103316943, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Linear(in_features=416, out_features=1632, bias=True)\n",
      "    (1): Dropout(p=0.178598433, inplace=False)\n",
      "    (2): PReLU(num_parameters=1)\n",
      "  )\n",
      "  (3): Linear(in_features=1632, out_features=1, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials = 12000, n_jobs= 5)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    # Save results to csv file\n",
    "    df = study.trials_dataframe().drop(['datetime_start', 'datetime_complete', 'duration'], axis=1)  # Exclude columns\n",
    "    df = df.loc[df['state'] == 'COMPLETE']        # Keep only results that did not prune\n",
    "    df = df.drop('state', axis=1)                 # Exclude state column\n",
    "    df = df.sort_values('value')                  # Sort based on accuracy\n",
    "    df.to_csv('op_2_freezing.csv', index=False)  # Save to csv file\n",
    "\n",
    "    # Display results in a dataframe\n",
    "    print(\"\\nOverall Results (ordered by accuracy):\\n {}\".format(df))\n",
    "\n",
    "    # Find the most important hyperparameters\n",
    "    most_important_parameters = optuna.importance.get_param_importances(study, target=None)\n",
    "\n",
    "    # Display the most important hyperparameters\n",
    "    print('\\nMost important hyperparameters:')\n",
    "    for key, value in most_important_parameters.items():\n",
    "        print('  {}:{}{:.2f}%'.format(key, (15-len(key))*' ', value*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
