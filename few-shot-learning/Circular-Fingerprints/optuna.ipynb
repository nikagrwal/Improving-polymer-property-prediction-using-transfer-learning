{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from psmiles import PolymerSmiles as PS\n",
    "from sklearn.metrics  import  mean_squared_error\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "from optuna.trial import TrialState \n",
    "\n",
    "random_seed = 123\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../data/updated_polymers.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3189133/2487804721.py:16: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  data_train_tensor = torch.tensor(data_train.reset_index(drop = True), dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "scalar = MinMaxScaler()\n",
    "data = df[\"fingerprint_circular\"]\n",
    "target = df[\"Egc\"]\n",
    "\n",
    "#data = data.values.reshape(-1, 1)  # Reshape data\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size=0.9, random_state=123)\n",
    "\n",
    "# Scaling target variable\n",
    "target_train = scalar.fit_transform(target_train.values.reshape(-1, 1))\n",
    "target_test = scalar.transform(target_test.values.reshape(-1, 1))\n",
    "\n",
    "# Creating tensors from data\n",
    "\n",
    "#Training Data\n",
    "data_train_tensor = torch.tensor(data_train.reset_index(drop = True), dtype=torch.float32)\n",
    "target_train_tensor = torch.tensor(target_train, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(data_train_tensor, target_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size= 32, shuffle= True)\n",
    "\n",
    "#Testing Data\n",
    "\n",
    "data_test_tensor = torch.tensor(data_test.reset_index(drop= True), dtype=torch.float32)\n",
    "target_test_tensor = torch.tensor(target_test, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(data_test_tensor, target_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(trial):\n",
    "    layers =  nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(2048, 1888),\n",
    "                nn.Dropout(0.296708814),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(1888, 416),\n",
    "                nn.Dropout(0.103316943),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            nn.Sequential(\n",
    "                nn.Linear(416, 1632),\n",
    "                nn.Dropout(0.178598433),\n",
    "                nn.PReLU()\n",
    "            ),\n",
    "            \n",
    "            nn.Linear(1632, 1)\n",
    "        ])\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    # Generate the model.\n",
    "    \n",
    "    model = define_model(trial)\n",
    "    state_dict = torch.load('../../models/molecule_circular.pth')\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    lr = 0.000364567\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    EPOCHS  = trial.suggest_int(\"EPOCHS\", 50, 700)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx,(data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(DEVICE), target.view(-1).to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.mse_loss(output.view(-1), target)\n",
    "            running_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss = running_loss / batch_idx\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                # Limiting validation data.\n",
    "\n",
    "                data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "                pred = model(data)\n",
    "                target_scaled = scalar.inverse_transform(target.cpu().numpy())\n",
    "                pred_scaled = scalar.inverse_transform(pred.cpu().detach().numpy())\n",
    "\n",
    "                test_loss = mean_squared_error(target_scaled, pred_scaled)\n",
    "                val_loss  += test_loss\n",
    "\n",
    "        avg_val_loss = val_loss/ batch_idx \n",
    "\n",
    "        trial.report(avg_val_loss, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-12-07 18:39:41,595] A new study created in memory with name: no-name-0ee343cf-4b79-477c-92e8-49c05f59046d\n",
      "[I 2023-12-07 19:13:10,995] Trial 3 finished with value: 0.635863916464294 and parameters: {'EPOCHS': 109}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 19:19:52,893] Trial 4 finished with value: 0.6534568979553684 and parameters: {'EPOCHS': 132}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 19:33:19,265] Trial 2 finished with value: 0.6510737587106317 and parameters: {'EPOCHS': 176}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 19:43:10,237] Trial 6 finished with value: 0.702363377560697 and parameters: {'EPOCHS': 77}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 19:45:56,575] Trial 0 finished with value: 0.6542010889817799 and parameters: {'EPOCHS': 218}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 19:46:38,375] Trial 7 pruned. \n",
      "[I 2023-12-07 19:47:30,579] Trial 10 pruned. \n",
      "[I 2023-12-07 19:47:47,740] Trial 11 pruned. \n",
      "[I 2023-12-07 19:53:11,416] Trial 12 pruned. \n",
      "[I 2023-12-07 20:08:06,764] Trial 9 finished with value: 0.6782962846744606 and parameters: {'EPOCHS': 68}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 20:08:43,854] Trial 14 pruned. \n",
      "[I 2023-12-07 20:12:35,400] Trial 15 pruned. \n",
      "[I 2023-12-07 20:12:54,991] Trial 16 pruned. \n",
      "[I 2023-12-07 20:13:11,496] Trial 17 pruned. \n",
      "[I 2023-12-07 20:13:50,176] Trial 18 pruned. \n",
      "[I 2023-12-07 20:14:27,474] Trial 19 pruned. \n",
      "[I 2023-12-07 20:15:19,949] Trial 20 pruned. \n",
      "[I 2023-12-07 20:15:58,325] Trial 21 pruned. \n",
      "[I 2023-12-07 20:17:47,193] Trial 22 pruned. \n",
      "[I 2023-12-07 20:18:45,572] Trial 23 pruned. \n",
      "[I 2023-12-07 20:19:41,660] Trial 24 pruned. \n",
      "[I 2023-12-07 20:19:59,941] Trial 25 pruned. \n",
      "[I 2023-12-07 20:37:24,962] Trial 26 finished with value: 0.740945025992449 and parameters: {'EPOCHS': 58}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 20:38:00,053] Trial 27 pruned. \n",
      "[I 2023-12-07 20:38:20,756] Trial 28 pruned. \n",
      "[I 2023-12-07 20:38:56,876] Trial 29 pruned. \n",
      "[I 2023-12-07 20:39:28,746] Trial 13 finished with value: 0.65583443080308 and parameters: {'EPOCHS': 149}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 20:40:54,887] Trial 31 pruned. \n",
      "[I 2023-12-07 20:41:14,151] Trial 32 pruned. \n",
      "[I 2023-12-07 20:41:32,742] Trial 33 pruned. \n",
      "[I 2023-12-07 20:42:09,700] Trial 34 pruned. \n",
      "[I 2023-12-07 20:42:43,604] Trial 30 pruned. \n",
      "[I 2023-12-07 20:45:27,260] Trial 36 pruned. \n",
      "[I 2023-12-07 20:45:46,494] Trial 37 pruned. \n",
      "[I 2023-12-07 20:46:04,102] Trial 38 pruned. \n",
      "[I 2023-12-07 20:47:00,488] Trial 39 pruned. \n",
      "[I 2023-12-07 20:47:33,457] Trial 40 pruned. \n",
      "[I 2023-12-07 20:48:12,516] Trial 41 pruned. \n",
      "[I 2023-12-07 20:48:31,920] Trial 42 pruned. \n",
      "[I 2023-12-07 20:48:51,688] Trial 43 pruned. \n",
      "[I 2023-12-07 20:49:59,383] Trial 44 pruned. \n",
      "[I 2023-12-07 20:50:16,054] Trial 45 pruned. \n",
      "[I 2023-12-07 20:50:54,174] Trial 46 pruned. \n",
      "[I 2023-12-07 20:51:24,792] Trial 47 pruned. \n",
      "[I 2023-12-07 21:11:54,940] Trial 35 finished with value: 0.6893206385259352 and parameters: {'EPOCHS': 99}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 21:12:51,033] Trial 49 pruned. \n",
      "[I 2023-12-07 21:13:10,559] Trial 50 pruned. \n",
      "[I 2023-12-07 21:13:47,218] Trial 51 pruned. \n",
      "[I 2023-12-07 21:14:00,402] Trial 52 pruned. \n",
      "[I 2023-12-07 21:14:13,918] Trial 53 pruned. \n",
      "[I 2023-12-07 21:14:31,392] Trial 54 pruned. \n",
      "[I 2023-12-07 21:15:09,744] Trial 55 pruned. \n",
      "[I 2023-12-07 21:15:27,311] Trial 56 pruned. \n",
      "[I 2023-12-07 21:16:24,501] Trial 57 pruned. \n",
      "[I 2023-12-07 21:16:43,855] Trial 58 pruned. \n",
      "[I 2023-12-07 21:17:04,097] Trial 59 pruned. \n",
      "[I 2023-12-07 21:18:18,372] Trial 60 pruned. \n",
      "[I 2023-12-07 21:19:19,894] Trial 61 pruned. \n",
      "[I 2023-12-07 21:19:40,557] Trial 62 pruned. \n",
      "[I 2023-12-07 21:20:01,166] Trial 63 pruned. \n",
      "[I 2023-12-07 21:20:21,886] Trial 64 pruned. \n",
      "[I 2023-12-07 21:21:03,178] Trial 65 pruned. \n",
      "[I 2023-12-07 21:21:44,504] Trial 66 pruned. \n",
      "[I 2023-12-07 21:22:26,619] Trial 67 pruned. \n",
      "[I 2023-12-07 21:22:44,698] Trial 68 pruned. \n",
      "[I 2023-12-07 21:23:03,888] Trial 69 pruned. \n",
      "[I 2023-12-07 21:23:40,362] Trial 70 pruned. \n",
      "[I 2023-12-07 21:23:57,652] Trial 71 pruned. \n",
      "[I 2023-12-07 21:24:31,326] Trial 72 pruned. \n",
      "[I 2023-12-07 21:24:47,447] Trial 73 pruned. \n",
      "[I 2023-12-07 21:25:06,951] Trial 74 pruned. \n",
      "[I 2023-12-07 21:25:23,016] Trial 75 pruned. \n",
      "[I 2023-12-07 21:25:55,852] Trial 76 pruned. \n",
      "[I 2023-12-07 21:27:08,465] Trial 77 pruned. \n",
      "[I 2023-12-07 21:27:28,803] Trial 78 pruned. \n",
      "[I 2023-12-07 21:27:47,283] Trial 79 pruned. \n",
      "[I 2023-12-07 21:28:23,516] Trial 80 pruned. \n",
      "[I 2023-12-07 21:28:42,742] Trial 81 pruned. \n",
      "[I 2023-12-07 21:29:21,628] Trial 82 pruned. \n",
      "[I 2023-12-07 21:29:37,902] Trial 83 pruned. \n",
      "[I 2023-12-07 21:30:15,341] Trial 84 pruned. \n",
      "[I 2023-12-07 21:30:35,117] Trial 85 pruned. \n",
      "[I 2023-12-07 21:31:13,870] Trial 86 pruned. \n",
      "[I 2023-12-07 21:31:17,367] Trial 48 finished with value: 0.643965124478864 and parameters: {'EPOCHS': 131}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 21:31:55,719] Trial 88 pruned. \n",
      "[I 2023-12-07 21:32:13,394] Trial 87 pruned. \n",
      "[I 2023-12-07 21:32:34,549] Trial 89 pruned. \n",
      "[I 2023-12-07 21:33:10,390] Trial 91 pruned. \n",
      "[I 2023-12-07 21:33:22,574] Trial 90 pruned. \n",
      "[I 2023-12-07 21:33:26,001] Trial 92 pruned. \n",
      "[I 2023-12-07 21:33:56,675] Trial 93 pruned. \n",
      "[I 2023-12-07 21:34:03,025] Trial 94 pruned. \n",
      "[I 2023-12-07 21:34:14,840] Trial 95 pruned. \n",
      "[I 2023-12-07 21:34:21,290] Trial 96 pruned. \n",
      "[I 2023-12-07 21:34:38,197] Trial 98 pruned. \n",
      "[I 2023-12-07 21:34:46,624] Trial 97 pruned. \n",
      "[I 2023-12-07 21:35:11,889] Trial 99 pruned. \n",
      "[I 2023-12-07 21:35:44,444] Trial 100 pruned. \n",
      "[I 2023-12-07 21:35:48,988] Trial 101 pruned. \n",
      "[I 2023-12-07 21:35:58,539] Trial 102 pruned. \n",
      "[I 2023-12-07 21:36:03,977] Trial 103 pruned. \n",
      "[I 2023-12-07 21:36:15,513] Trial 104 pruned. \n",
      "[I 2023-12-07 21:36:51,188] Trial 106 pruned. \n",
      "[I 2023-12-07 21:37:22,122] Trial 107 pruned. \n",
      "[I 2023-12-07 21:37:30,013] Trial 105 pruned. \n",
      "[I 2023-12-07 21:37:39,903] Trial 108 pruned. \n",
      "[I 2023-12-07 21:38:13,831] Trial 110 pruned. \n",
      "[I 2023-12-07 21:38:21,674] Trial 109 pruned. \n",
      "[I 2023-12-07 21:38:31,075] Trial 111 pruned. \n",
      "[I 2023-12-07 21:39:00,151] Trial 112 pruned. \n",
      "[I 2023-12-07 21:39:18,765] Trial 114 pruned. \n",
      "[I 2023-12-07 21:39:23,716] Trial 113 pruned. \n",
      "[I 2023-12-07 21:39:38,745] Trial 115 pruned. \n",
      "[I 2023-12-07 21:39:43,216] Trial 116 pruned. \n",
      "[I 2023-12-07 21:40:36,867] Trial 117 pruned. \n",
      "[I 2023-12-07 21:40:40,352] Trial 118 pruned. \n",
      "[I 2023-12-07 21:41:30,819] Trial 119 pruned. \n",
      "[I 2023-12-07 21:41:45,632] Trial 121 pruned. \n",
      "[I 2023-12-07 21:42:21,253] Trial 122 pruned. \n",
      "[I 2023-12-07 21:42:39,735] Trial 123 pruned. \n",
      "[I 2023-12-07 21:42:58,955] Trial 124 pruned. \n",
      "[I 2023-12-07 21:58:24,650] Trial 125 pruned. \n",
      "[I 2023-12-07 21:58:43,315] Trial 126 pruned. \n",
      "[I 2023-12-07 21:59:02,448] Trial 127 pruned. \n",
      "[I 2023-12-07 21:59:41,140] Trial 128 pruned. \n",
      "[I 2023-12-07 21:59:41,400] Trial 1 finished with value: 0.7077102386730524 and parameters: {'EPOCHS': 657}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 22:00:16,933] Trial 129 pruned. \n",
      "[I 2023-12-07 22:00:18,175] Trial 130 pruned. \n",
      "[I 2023-12-07 22:00:34,899] Trial 131 pruned. \n",
      "[I 2023-12-07 22:00:53,283] Trial 132 pruned. \n",
      "[I 2023-12-07 22:01:12,138] Trial 134 pruned. \n",
      "[I 2023-12-07 22:01:30,379] Trial 135 pruned. \n",
      "[I 2023-12-07 22:02:00,830] Trial 133 pruned. \n",
      "[I 2023-12-07 22:02:04,701] Trial 136 pruned. \n",
      "[I 2023-12-07 22:02:17,469] Trial 137 pruned. \n",
      "[I 2023-12-07 22:02:22,215] Trial 138 pruned. \n",
      "[I 2023-12-07 22:02:41,611] Trial 140 pruned. \n",
      "[I 2023-12-07 22:02:59,075] Trial 141 pruned. \n",
      "[I 2023-12-07 22:03:48,901] Trial 139 pruned. \n",
      "[I 2023-12-07 22:03:50,483] Trial 142 pruned. \n",
      "[I 2023-12-07 22:04:07,650] Trial 143 pruned. \n",
      "[I 2023-12-07 22:04:09,659] Trial 144 pruned. \n",
      "[I 2023-12-07 22:04:23,757] Trial 145 pruned. \n",
      "[I 2023-12-07 22:04:42,050] Trial 147 pruned. \n",
      "[I 2023-12-07 22:04:55,707] Trial 148 pruned. \n",
      "[I 2023-12-07 22:04:57,256] Trial 146 pruned. \n",
      "[I 2023-12-07 22:05:14,844] Trial 150 pruned. \n",
      "[I 2023-12-07 22:05:28,981] Trial 149 pruned. \n",
      "[I 2023-12-07 22:06:20,157] Trial 151 pruned. \n",
      "[I 2023-12-07 22:06:21,266] Trial 152 pruned. \n",
      "[I 2023-12-07 22:06:37,012] Trial 154 pruned. \n",
      "[I 2023-12-07 22:07:08,661] Trial 155 pruned. \n",
      "[I 2023-12-07 22:07:24,812] Trial 153 pruned. \n",
      "[I 2023-12-07 22:07:26,636] Trial 156 pruned. \n",
      "[I 2023-12-07 22:07:45,234] Trial 157 pruned. \n",
      "[I 2023-12-07 22:07:46,177] Trial 158 pruned. \n",
      "[I 2023-12-07 22:08:03,999] Trial 160 pruned. \n",
      "[I 2023-12-07 22:08:23,252] Trial 159 pruned. \n",
      "[I 2023-12-07 22:08:24,536] Trial 161 pruned. \n",
      "[I 2023-12-07 22:08:40,257] Trial 162 pruned. \n",
      "[I 2023-12-07 22:08:40,990] Trial 163 pruned. \n",
      "[I 2023-12-07 22:09:00,363] Trial 165 pruned. \n",
      "[I 2023-12-07 22:09:18,012] Trial 164 pruned. \n",
      "[I 2023-12-07 22:09:18,174] Trial 166 pruned. \n",
      "[I 2023-12-07 22:09:37,220] Trial 168 pruned. \n",
      "[I 2023-12-07 22:09:38,651] Trial 167 pruned. \n",
      "[I 2023-12-07 22:09:57,834] Trial 170 pruned. \n",
      "[I 2023-12-07 22:10:14,568] Trial 169 pruned. \n",
      "[I 2023-12-07 22:10:31,068] Trial 171 pruned. \n",
      "[I 2023-12-07 22:10:49,707] Trial 173 pruned. \n",
      "[I 2023-12-07 22:10:49,998] Trial 172 pruned. \n",
      "[I 2023-12-07 22:11:08,248] Trial 175 pruned. \n",
      "[I 2023-12-07 22:11:27,084] Trial 174 pruned. \n",
      "[I 2023-12-07 22:11:28,264] Trial 176 pruned. \n",
      "[I 2023-12-07 22:11:47,699] Trial 178 pruned. \n",
      "[I 2023-12-07 22:12:07,919] Trial 179 pruned. \n",
      "[I 2023-12-07 22:12:48,102] Trial 180 pruned. \n",
      "[I 2023-12-07 22:13:02,161] Trial 177 pruned. \n",
      "[I 2023-12-07 22:13:16,563] Trial 182 pruned. \n",
      "[I 2023-12-07 22:13:32,758] Trial 183 pruned. \n",
      "[I 2023-12-07 22:13:53,496] Trial 184 pruned. \n",
      "[I 2023-12-07 22:14:13,565] Trial 185 pruned. \n",
      "[I 2023-12-07 22:14:21,034] Trial 181 pruned. \n",
      "[I 2023-12-07 22:14:33,849] Trial 186 pruned. \n",
      "[I 2023-12-07 22:14:50,568] Trial 188 pruned. \n",
      "[I 2023-12-07 22:14:55,361] Trial 187 pruned. \n",
      "[I 2023-12-07 22:15:14,992] Trial 190 pruned. \n",
      "[I 2023-12-07 22:15:28,880] Trial 189 pruned. \n",
      "[I 2023-12-07 22:15:48,148] Trial 192 pruned. \n",
      "[I 2023-12-07 22:15:54,691] Trial 191 pruned. \n",
      "[I 2023-12-07 22:16:06,648] Trial 193 pruned. \n",
      "[I 2023-12-07 22:16:23,214] Trial 195 pruned. \n",
      "[I 2023-12-07 22:16:43,154] Trial 196 pruned. \n",
      "[I 2023-12-07 22:17:20,832] Trial 197 pruned. \n",
      "[I 2023-12-07 22:17:59,169] Trial 198 pruned. \n",
      "[I 2023-12-07 22:18:33,096] Trial 194 pruned. \n",
      "[I 2023-12-07 22:18:48,051] Trial 199 pruned. \n",
      "[I 2023-12-07 22:18:51,155] Trial 200 pruned. \n",
      "[I 2023-12-07 22:19:06,068] Trial 201 pruned. \n",
      "[I 2023-12-07 22:19:11,349] Trial 5 finished with value: 0.6966178243933457 and parameters: {'EPOCHS': 615}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 22:19:24,377] Trial 203 pruned. \n",
      "[I 2023-12-07 22:19:30,790] Trial 204 pruned. \n",
      "[I 2023-12-07 22:19:43,372] Trial 205 pruned. \n",
      "[I 2023-12-07 22:19:50,338] Trial 206 pruned. \n",
      "[I 2023-12-07 22:20:03,846] Trial 207 pruned. \n",
      "[I 2023-12-07 22:20:10,678] Trial 208 pruned. \n",
      "[I 2023-12-07 22:20:24,516] Trial 202 pruned. \n",
      "[I 2023-12-07 22:20:50,104] Trial 210 pruned. \n",
      "[I 2023-12-07 22:21:09,685] Trial 212 pruned. \n",
      "[I 2023-12-07 22:21:20,784] Trial 209 pruned. \n",
      "[I 2023-12-07 22:21:21,047] Trial 211 pruned. \n",
      "[I 2023-12-07 22:21:41,820] Trial 215 pruned. \n",
      "[I 2023-12-07 22:21:42,138] Trial 214 pruned. \n",
      "[I 2023-12-07 22:22:03,070] Trial 217 pruned. \n",
      "[I 2023-12-07 22:22:24,449] Trial 218 pruned. \n",
      "[I 2023-12-07 22:22:45,393] Trial 219 pruned. \n",
      "[I 2023-12-07 22:23:12,982] Trial 213 pruned. \n",
      "[I 2023-12-07 22:23:26,068] Trial 220 pruned. \n",
      "[I 2023-12-07 22:23:53,030] Trial 221 pruned. \n",
      "[I 2023-12-07 22:24:05,348] Trial 222 pruned. \n",
      "[I 2023-12-07 22:24:12,002] Trial 223 pruned. \n",
      "[I 2023-12-07 22:24:37,903] Trial 224 pruned. \n",
      "[I 2023-12-07 22:24:44,705] Trial 225 pruned. \n",
      "[I 2023-12-07 22:24:57,653] Trial 226 pruned. \n",
      "[I 2023-12-07 22:25:04,476] Trial 227 pruned. \n",
      "[I 2023-12-07 22:25:17,119] Trial 228 pruned. \n",
      "[I 2023-12-07 22:25:42,557] Trial 229 pruned. \n",
      "[I 2023-12-07 22:26:02,176] Trial 231 pruned. \n",
      "[I 2023-12-07 22:26:12,951] Trial 230 pruned. \n",
      "[I 2023-12-07 22:26:18,708] Trial 232 pruned. \n",
      "[I 2023-12-07 22:26:47,770] Trial 233 pruned. \n",
      "[I 2023-12-07 22:26:54,495] Trial 234 pruned. \n",
      "[I 2023-12-07 22:27:13,112] Trial 236 pruned. \n",
      "[I 2023-12-07 22:28:29,367] Trial 237 pruned. \n",
      "[I 2023-12-07 22:28:49,768] Trial 238 pruned. \n",
      "[I 2023-12-07 22:39:50,021] Trial 8 finished with value: 0.699875994350636 and parameters: {'EPOCHS': 580}. Best is trial 3 with value: 0.635863916464294.\n",
      "[I 2023-12-07 22:50:15,769] Trial 240 pruned. \n",
      "[I 2023-12-07 22:50:33,013] Trial 241 pruned. \n",
      "[I 2023-12-07 22:51:05,087] Trial 242 pruned. \n",
      "[I 2023-12-07 22:51:21,697] Trial 243 pruned. \n",
      "[I 2023-12-07 22:51:40,145] Trial 244 pruned. \n",
      "[I 2023-12-07 22:52:00,179] Trial 245 pruned. \n",
      "[I 2023-12-07 22:52:20,295] Trial 246 pruned. \n",
      "[I 2023-12-07 22:52:36,823] Trial 247 pruned. \n",
      "[I 2023-12-07 22:52:51,233] Trial 248 pruned. \n",
      "[I 2023-12-07 22:53:10,859] Trial 249 pruned. \n",
      "[I 2023-12-07 22:53:29,348] Trial 250 pruned. \n",
      "[I 2023-12-07 22:54:07,549] Trial 251 pruned. \n",
      "[I 2023-12-07 22:54:47,981] Trial 252 pruned. \n",
      "[I 2023-12-07 22:55:05,741] Trial 253 pruned. \n",
      "[I 2023-12-07 22:55:26,589] Trial 254 pruned. \n",
      "[I 2023-12-07 22:56:56,895] Trial 255 pruned. \n",
      "[I 2023-12-07 22:57:55,209] Trial 256 pruned. \n",
      "[I 2023-12-07 22:58:15,328] Trial 257 pruned. \n",
      "[I 2023-12-07 22:58:33,696] Trial 258 pruned. \n",
      "[I 2023-12-07 22:58:52,303] Trial 259 pruned. \n",
      "[I 2023-12-07 22:59:10,887] Trial 260 pruned. \n",
      "[I 2023-12-07 22:59:29,504] Trial 261 pruned. \n",
      "[I 2023-12-07 22:59:49,608] Trial 262 pruned. \n",
      "[I 2023-12-07 23:00:05,568] Trial 263 pruned. \n",
      "[I 2023-12-07 23:00:24,601] Trial 264 pruned. \n",
      "[I 2023-12-07 23:01:00,381] Trial 265 pruned. \n",
      "[I 2023-12-07 23:01:37,422] Trial 266 pruned. \n",
      "[I 2023-12-07 23:02:12,273] Trial 267 pruned. \n",
      "[I 2023-12-07 23:02:51,745] Trial 268 pruned. \n",
      "[I 2023-12-07 23:03:11,642] Trial 269 pruned. \n",
      "[I 2023-12-07 23:03:28,655] Trial 270 pruned. \n",
      "[I 2023-12-07 23:04:04,900] Trial 271 pruned. \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials = 700, n_jobs= 5)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "\n",
    "    # Save results to csv file\n",
    "    df = study.trials_dataframe().drop(['datetime_start', 'datetime_complete', 'duration'], axis=1)  # Exclude columns\n",
    "    df = df.loc[df['state'] == 'COMPLETE']        # Keep only results that did not prune\n",
    "    df = df.drop('state', axis=1)                 # Exclude state column\n",
    "    df = df.sort_values('value')                  # Sort based on accuracy\n",
    "    df.to_csv('op_no_freezing.csv', index=False)  # Save to csv file\n",
    "\n",
    "    # Display results in a dataframe\n",
    "    print(\"\\nOverall Results (ordered by accuracy):\\n {}\".format(df))\n",
    "\n",
    "    # Find the most important hyperparameters\n",
    "    most_important_parameters = optuna.importance.get_param_importances(study, target=None)\n",
    "\n",
    "    # Display the most important hyperparameters\n",
    "    print('\\nMost important hyperparameters:')\n",
    "    for key, value in most_important_parameters.items():\n",
    "        print('  {}:{}{:.2f}%'.format(key, (15-len(key))*' ', value*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
